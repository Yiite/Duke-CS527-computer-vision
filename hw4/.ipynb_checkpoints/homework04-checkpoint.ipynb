{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "T"
    ]
   },
   "source": [
    "> **Student Names and IDs**:\n",
    ">\n",
    "> - Student 1, ID1 (Replace this item with your first and last name and student ID number.\n",
    "Add more items like this as needed, including the `> -` characters at the beginning,\n",
    "which generate the indent and the bullet.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "## Part 1: Exam-Style Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "Suppose that the histogram of orientations $\\theta\\in [0, 180)$ has 18 equal bins, numbered 0 to 17, and with centers $5, 15, \\ldots, 175$. Bilinear voting is used, as described in the class notes on Histograms of Oriented Gradients. Give the fraction of vote that each of the bins receives when a measurement $\\theta = 42$ is observed. Fractions are values in $[0, 1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "The $x$ and $y$ components of $\\nabla I$ at a particular pixel in an image are $10\\sqrt{3}$ and $10$, respectively. What are the magnitude and orientation of the gradient there? Express orientation in degrees relative to the $x$ axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "A HOG feature is computed from a $128\\times 64$ window divided into cells with $8\\times 8$ pixels each. The size of a block is $2\\times 2$ cells. Central differences are used to compute gradients. Each cell histogram has nine bins of equal size, and bin 0 is for orientations in $[0, 20)$ degrees.\n",
    "\n",
    "Rather than using a constant $\\epsilon$ in the denominator during normalization of a histogram $\\mathbf{v}$, the following procedure is used at all stages to normalize a histogram $\\mathbf{v}$ to $\\mathbf{v}'$:\n",
    "\n",
    "$$\n",
    "\\mathbf{v'} \\;=\\; \\left\\{\\begin{array}{ll} \\frac{\\mathbf{v}}{\\|\\mathbf{v}\\|} &\n",
    "\\mbox{if $\\|\\mathbf{v}\\| \\neq 0$} \\\\ \\mathbf{v} & \\mbox{otherwise.}\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "The threshold $\\tau$ used to saturate the feature entries during contrast normalization is set to infinity (so that it has no effect).\n",
    "\n",
    "For a given window, the pixel at position $(5, 5)$ has value 50, and all other pixels are zero.\n",
    "\n",
    "Give an expression for the entries of the HOG feature $\\mathbf{h}$ for that window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "The magnitude of a vector $\\mathbf{x} = [x, y]^T\\in\\mathbb{R}^2$ is\n",
    "\n",
    "$$\n",
    "            f(x, y) = \\sqrt{x^2 + y^2}\\;.\n",
    "$$\n",
    "\n",
    "Write algebraic expressions and exact decimal numerical values of the gradient $\\nabla f$ and Hessian $H_f$ of $f$ at $x=3$ and $y=4$.\n",
    "\n",
    "[Hint: $1/5^3 = 1/125 = 8/1000$.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "The second stage of line search repeatedly narrows a bracketing triple $(a, b, c)$ established in the first stage. Suppose that at some point during the second stage the bracketing triple is:\n",
    "\n",
    "$$\n",
    "a = 0 \\;\\;\\;,\\;\\;\\; b = 2 \\;\\;\\;,\\;\\;\\; c = 6\n",
    "$$\n",
    "\n",
    "with function values\n",
    "\n",
    "$$\n",
    "h(a) = 6 \\;\\;\\;,\\;\\;\\; h(b) = 3 \\;\\;\\;,\\;\\;\\; h(c) = 4\n",
    "$$\n",
    "\n",
    "along the search line. Assume further that\n",
    "\n",
    "$$\n",
    "h(1) = 2 \\;\\;\\;\\text{and}\\;\\;\\; h(4) = 5\\;.\n",
    "$$\n",
    "\n",
    "What is the bracketing triple after that? Standard line search is applied, that is, no golden ratio is used. No need to explain.\n",
    "\n",
    "[Hint: Draw a sketch.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "The gradient and Hessian at $\\mathbf{z}_0 = [4, 1]^T$ for some function $f\\ :\\ \\mathbb{R}^2 \\rightarrow \\mathbb{R}$ are as follows:\n",
    "\n",
    "$$\n",
    "\\nabla f(\\mathbf{z}_0) \\;=\\; \\left[\\begin{array}{c}2\\\\1 \\end{array}\\right]\n",
    "\\;\\;\\;\\text{and}\\;\\;\\;\n",
    "H_f(\\mathbf{z}_0) \\;=\\; \\left[\\begin{array}{c}2 & 1\\\\1 & 3 \\end{array}\\right] \\;.\n",
    "$$\n",
    "\n",
    "Find the point $\\mathbf{z}_1$ that results by taking a single Newton step from $\\mathbf{z}_0$. Show your reasoning briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "A classification problem asks to find a classifier $h\\in\\mathcal{H}$ whose domain $X$ and co-domain $Y$ of $h$ are defined as follows:\n",
    "\n",
    "$$\n",
    "X = \\{0, 2, 4, 6, 8, 10\\} \\;\\;\\;\\text{and}\\;\\;\\; Y = \\{0, 1\\}\n",
    "$$\n",
    "\n",
    "and the hypothesis space $\\mathcal{H}$ is the set of the following five functions\n",
    "\n",
    "$$\n",
    "h_k(x) = \\left\\{\\begin{array}{ll}0 & \\mbox{if $x < k$}\\\\\n",
    "1 & \\mbox{otherwise}\\end{array}\\right.\n",
    "\\;\\;\\;\\text{for}\\;\\;\\; k = 1, 3, 5, 7, 9\\;.\n",
    "$$\n",
    "\n",
    "The following tiny training set is given:\n",
    "\n",
    "$$\n",
    "T = \\{(0, 0), (2, 0), (4, 1), (6, 1) \\} \\;.\n",
    "$$\n",
    "\n",
    "Make a table of the training risk $L_T(h_k)$ for $k = 1, 3, 5, 7, 9$.  Express values in percent. Then use the table to determine the optimal classifier $\\hat{h}$ for this training set (thus, we only care about empirical risk here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "T"
    ]
   },
   "source": [
    "(Remove this line and complete the expressions below).\n",
    "\n",
    "$$\n",
    "\\begin{array}{r|ccccc}\n",
    "k & 1 & 3 & 5 & 7 & 9 \\\\\\hline\n",
    "L_T(h_k) &  &  &  &  &  \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The optimal classifier on $T$ is $\\hat{k} = $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "Assume that the probability model $p(x, y)$ for the data in Problem 1.7 is as specified in the table below. The table contains the joint probability $p(x, y)$ with values expressed in percent, rather than as numbers in $[0, 1]$. It has one column per value of $x$ and one row per value of $y$.\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|ccccccc}\n",
    " & 0 & 2 & 4 & 6 & 8 & 10 \\\\\\hline\n",
    "0 & 12 & 11 & 10 & 7 & 6 & 4 \\\\\n",
    "1 & 2 & 4 & 6 & 10 & 12 & 16\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Under the same circumstances as in Problem 1.7, and with the probability model above, make a table of the statistical risk $L_p(h)$ and determine the classifier that generalizes best. Express values in percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "T"
    ]
   },
   "source": [
    "(Remove this line and complete the expressions below).\n",
    "\n",
    "$$\n",
    "\\begin{array}{r|ccccc}\n",
    "k & 1 & 3 & 5 & 7 & 9 \\\\\\hline\n",
    "L_p(h_k) &  &  &  &  &  \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The classifier that generalizes best is $\\hat{k} = $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "## Part 2: Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "What is the shape (number of rows and columns) of $U$? Explain briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "Explain clearly how, given $\\mathbf{u}$, you can use the Singular Value Decomposition (SVD) to compute a matrix whose columns form an orthonormal basis for $\\mathcal{O}(\\mathbf{u})$. Also explain why.\n",
    "\n",
    "Then show a basis for $\\mathcal{O}([1, 1, 0]^T)$ using your technique.\n",
    "\n",
    "Give the projection matrix $P$ for this space, and the projection of the vector $\\mathbf{b} = [0, 2, -4]^T$ onto $\\mathcal{O}([1, 1, 0]^T)$.\n",
    "\n",
    "Use whatever code you'd like, but do **not** submit your code. Give your numerical results either exactly (if you can guess what they are) or with four decimal digits after the period.\n",
    "\n",
    "Do **not** use any other techniques, such as Gram-Schmidt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "For each of the two matrices $U$ and $P$ and the vector $\\mathbf{p}$ you found in the previous problem, state whether the object is unique, and explain briefly why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "Compute the matrix $$Q = I - \\mathbf{n}\\mathbf{n}^T$$ for the example given in Problem 2.2.\n",
    "\n",
    "Show $Q$ if it is different from the matrix $P$ you obtained through SVD. Otherwise, just state that the two matrices are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "## Part 3: Optimization and the SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "def normalize(v):\n",
    "    n = np.linalg.norm(v)\n",
    "    if n > 0:\n",
    "        v = v / n\n",
    "    return v, n\n",
    "\n",
    "# sphere_search returns a new point z1, not a search step size\n",
    "def sphere_step(f, g, z0, epsilon=1.e-6, args=()):\n",
    "    assert epsilon > 0 and epsilon < 1, 'epsilon must be in (0, 1)'\n",
    "    assert z0.size > 1, 'sphere must be at least 2-dimensional'\n",
    "    \n",
    "    n0, delta = 0, 0\n",
    "    while n0 < epsilon:\n",
    "        z0 += delta * np.sqrt(epsilon) * np.random.random(z0.shape)\n",
    "        z0, _ = normalize(z0)\n",
    "        p0 = -g(z0, *args)  # Starting direction\n",
    "        # Project p0 onto the tangent hyperplane to the sphere at z0 and normalize\n",
    "        s0, n0 = normalize(p0 - np.dot(z0, p0) * z0)\n",
    "        delta = 1\n",
    "    \n",
    "    def h(theta, args):\n",
    "        return f(z0 * np.cos(theta) + s0 * np.sin(theta), args)\n",
    "    \n",
    "    res = minimize_scalar(h, bracket=(0, 1), args=args)\n",
    "    theta = res.x\n",
    "    return z0 * np.cos(theta) + s0 * np.sin(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "Write a function with the following header and `assert` statements:\n",
    "\n",
    "    def first(A, epsilon=1.e-6, maxiter=10):\n",
    "        assert A.size > 0, 'array cannot be empty'\n",
    "        assert np.max(np.abs(A)) >= epsilon, 'array cannot be zero'\n",
    "\n",
    "that uses `sphere_step` iteratively to return the tuple `u, sigma, v` of the first left singular vector, first singular value, and first right singular vector of `A`.\n",
    "\n",
    "Show your code and the results of running the given tests. You may want to compare your results with those obtained with an off-the-shelf implementation of the SVD. However, do **not** submit your comparison, and do not use SVDs anywhere in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "T"
    ]
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "outputs": [],
   "source": [
    "def test(f, A_list):\n",
    "    def printArray(name, A):\n",
    "        print(name, A, sep='\\n', end='\\n\\n')\n",
    "        \n",
    "    if f.__name__ is 'first':\n",
    "        un, sn, vn = 'u', 'sigma', 'v'\n",
    "        product = False\n",
    "    else:\n",
    "        un, sn, vn = 'U', 'Sigma', 'V'\n",
    "        product = True\n",
    "\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    \n",
    "    for A in A_list:\n",
    "        U, Sigma, V = f(A)\n",
    "        print('=' * 10, 'testing', f.__name__, '=' * 10)\n",
    "        printArray('A', A)\n",
    "        if product:\n",
    "            printArray(\"U * Sigma * V'\", np.dot(U, np.dot(Sigma, V.T)))\n",
    "        printArray(un, U)\n",
    "        printArray(sn, Sigma)\n",
    "        printArray(vn, V)\n",
    "            \n",
    "s3 = np.sqrt(3)\n",
    "A_list = (np.array([[s3, s3], [-3., 3.], [1., 1.]]) / np.sqrt(2.),\n",
    "          np.outer([1., 2., 3.], [2., 0., -1., 3.]),\n",
    "          np.array([[3.], [0.], [4.]]), np.array([[4., -3.]]))\n",
    "\n",
    "try:\n",
    "    test(first, A_list)\n",
    "except NameError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "### Problem 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "HST"
    ]
   },
   "source": [
    "Use your function `first` to write a function with the following header and `assert` statement that computes the \"tiny\" SVD of a non-empty matrix $A$, with the given specifications:\n",
    "\n",
    "    def SVD(A, epsilon=1.e-3, maxiter=10):\n",
    "        assert A.size > 0, 'array cannot be empty'\n",
    "        \n",
    "The function should return the tuple `U, Sigma, V` of the matrices in the \"tiny\" SVD of `A`, and should comply with the programming notes.\n",
    "        \n",
    "Show your code and the results of running the given tests. You may want to compare your results with those obtained with an off-the-shelf implementation of the SVD. However, do **not** submit your comparison. Do not use library SVDs anywhere in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "T"
    ]
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "ST"
    ]
   },
   "outputs": [],
   "source": [
    "s3 = np.sqrt(3)\n",
    "A_list = (np.array([[s3, s3], [-3., 3.], [1., 1.]]) / np.sqrt(2.),\n",
    "          np.outer([1., 2., 3.], [2., 0., -1., 3.]),\n",
    "          np.array([[3.], [0.], [4.]]), np.array([[4., -3.]]))\n",
    "\n",
    "try:\n",
    "    test(SVD, A_list)\n",
    "except NameError:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
